services:
  dev-postgres-db:
    image: postgres:15
    ports:
    - 5432:5432
    environment:
    - POSTGRES_PASSWORD=postgres
    volumes:
    - postgres-data:/var/lib/postgresql/data
    - ./postgres/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5
  dev-luigi-python:
    build: python
    ports:
    - 8082:8082
    depends_on:
      dev-postgres-db:
        condition: service_healthy
    restart: on-failure
  dev-grafana:
      build:
        context: ./grafana
      restart: always
      ports:
        - "8080:3000"
      depends_on:
        - dev-postgres-db
      volumes:
        - grafana-storage:/var/lib/grafana
  dev-mcp-server:
    build:
      context: ./mcp_server
    depends_on:
      dev-postgres-db:
        condition: service_healthy
    environment:
      - DB_HOST=dev-postgres-db
      - DB_PORT=5432
      - DB_NAME=postgres
      - DB_USER=postgres
      - DB_PASSWORD=postgres
    restart: unless-stopped
    stdin_open: true
    tty: true
  dev-nlq-service:
    build:
      context: ./nlq_service
    depends_on:
      dev-postgres-db:
        condition: service_healthy
      dev-ollama:
        condition: service_started
    environment:
      - DB_HOST=dev-postgres-db
      - DB_PORT=5432
      - DB_NAME=postgres
      - DB_USER=postgres
      - DB_PASSWORD=postgres
      - LLM_PROVIDER=${LLM_PROVIDER:-openai}
      - LLM_API_KEY=${LLM_API_KEY:-}
      - LLM_MODEL=${LLM_MODEL:-gpt-4o-mini}
      - LLM_BASE_URL=${LLM_BASE_URL:-http://dev-ollama:11434/v1}
    ports:
      - "8000:8000"
    restart: unless-stopped
  dev-data-quality-agent:
    build:
      context: ./data_quality_agent
    depends_on:
      dev-postgres-db:
        condition: service_healthy
      dev-ollama:
        condition: service_started
    environment:
      - DB_HOST=dev-postgres-db
      - DB_PORT=5432
      - DB_NAME=postgres
      - DB_USER=postgres
      - DB_PASSWORD=postgres
      - LLM_PROVIDER=${LLM_PROVIDER:-openai}
      - LLM_API_KEY=${LLM_API_KEY:-}
      - LLM_MODEL=${LLM_MODEL:-gpt-4o-mini}
      - LLM_BASE_URL=${LLM_BASE_URL:-http://dev-ollama:11434/v1}
    ports:
      - "8001:8001"
    restart: unless-stopped
  dev-predictive-maintenance-agent:
    build:
      context: ./predictive_maintenance_agent
    depends_on:
      dev-postgres-db:
        condition: service_healthy
      dev-ollama:
        condition: service_started
    environment:
      - DB_HOST=dev-postgres-db
      - DB_PORT=5432
      - DB_NAME=postgres
      - DB_USER=postgres
      - DB_PASSWORD=postgres
      - LLM_PROVIDER=${LLM_PROVIDER:-openai}
      - LLM_API_KEY=${LLM_API_KEY:-}
      - LLM_MODEL=${LLM_MODEL:-gpt-4o-mini}
      - LLM_BASE_URL=${LLM_BASE_URL:-http://dev-ollama:11434/v1}
    ports:
      - "8003:8003"
    restart: unless-stopped
  dev-ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    restart: unless-stopped
    # Optional: pre-pull models on startup
    # Uncomment to automatically download models
    # command: >
    #   sh -c "ollama serve & sleep 5 && 
    #          ollama pull llama3.1 && 
    #          ollama pull mistral && 
    #          wait"
volumes:
  postgres-data:
  grafana-storage:
  ollama-data:
 