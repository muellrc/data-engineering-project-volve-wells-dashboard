{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original link to Open Data for Oil and Gas: Volve Dataset\n",
    "#https://datavillagesa.blob.core.windows.net/volve?sv=2018-03-28&sr=c&sig=DtgCD8%2FCnMUZgKkm21ZE9g4hPnLlMCwQtZXqF4eDTg8%3D&se=2022-05-02T17%3A03%3A55Z&sp=rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml.etree import Element, XMLParser, parse\n",
    "from typing import Any\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['/Users/christianmueller/Library/Mobile Documents/com~apple~CloudDocs/Studies/Academic/5. MSc CS/2022/2022.1/7. DLMDSEDE02 Project Data Engineering/4. Assignments/Deliverables/DLMDSEDE02-project-cmueller/python/source-files/VolveF.edm.1.xml',\n",
    " '/Users/christianmueller/Library/Mobile Documents/com~apple~CloudDocs/Studies/Academic/5. MSc CS/2022/2022.1/7. DLMDSEDE02 Project Data Engineering/4. Assignments/Deliverables/DLMDSEDE02-project-cmueller/python/source-files/VolveF.edm.2.xml', \n",
    " '/Users/christianmueller/Library/Mobile Documents/com~apple~CloudDocs/Studies/Academic/5. MSc CS/2022/2022.1/7. DLMDSEDE02 Project Data Engineering/4. Assignments/Deliverables/DLMDSEDE02-project-cmueller/python/source-files/VolveF.edm.3.xml',\n",
    "  '/Users/christianmueller/Library/Mobile Documents/com~apple~CloudDocs/Studies/Academic/5. MSc CS/2022/2022.1/7. DLMDSEDE02 Project Data Engineering/4. Assignments/Deliverables/DLMDSEDE02-project-cmueller/python/source-files/VolveF.edm.4.xml',\n",
    "   '/Users/christianmueller/Library/Mobile Documents/com~apple~CloudDocs/Studies/Academic/5. MSc CS/2022/2022.1/7. DLMDSEDE02 Project Data Engineering/4. Assignments/Deliverables/DLMDSEDE02-project-cmueller/python/source-files/VolveF.edm.5.xml',\n",
    "    '/Users/christianmueller/Library/Mobile Documents/com~apple~CloudDocs/Studies/Academic/5. MSc CS/2022/2022.1/7. DLMDSEDE02 Project Data Engineering/4. Assignments/Deliverables/DLMDSEDE02-project-cmueller/python/source-files/VolveF.edm.6.xml']\n",
    "with open('Volve F.edm.xml', 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Access EDM File in external cloud storage\n",
    "\n",
    "path = str(os.path.abspath(''))\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://drive.google.com/uc?export=download&confirm=yTib\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_id = '1HubrQY1zUw_vDflNvXnhKgv5bJXQZ9kd'\n",
    "    destination = str(path + \"/Volve F.edm.xml\")\n",
    "    download_file_from_google_drive(file_id, destination)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edm_file = r\"source_files/Volve F.edm.xml\"\n",
    "\n",
    "# parse EDM xml file \n",
    "p = XMLParser(huge_tree=True)\n",
    "tree = parse(\"/Users/christianmueller/Library/Mobile Documents/com~apple~CloudDocs/Studies/Academic/5. MSc CS/2022/2022.1/7. DLMDSEDE02 Project Data Engineering/4. Assignments/Deliverables/DLMDSEDE02-project-cmueller/tests-and-examples/Volve F.edm.xml\", parser=p)\n",
    "root = tree.getroot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml.etree import Element, XMLParser, parse\n",
    "from typing import Any\n",
    "import csv\n",
    "\n",
    "p = XMLParser(huge_tree=True)\n",
    "tree = parse(\"/Users/christianmueller/Library/Mobile Documents/com~apple~CloudDocs/Studies/Academic/5. MSc CS/2022/2022.1/7. DLMDSEDE02 Project Data Engineering/4. Assignments/Deliverables/DLMDSEDE02-project-cmueller/tests-and-examples/Volve F.edm.xml\", parser=p)\n",
    "root = tree.getroot()\n",
    "\n",
    "result_values = []\n",
    "result_values = root.findall(\"CD_WELL\")\n",
    "\n",
    "with open('test.csv', 'w') as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    for result_value in result_values:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(result_value.items())\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml.etree import Element, XMLParser, parse\n",
    "from typing import Any\n",
    "import csv\n",
    "\n",
    "p = XMLParser(huge_tree=True)\n",
    "tree = parse(\"/Users/christianmueller/Library/Mobile Documents/com~apple~CloudDocs/Studies/Academic/5. MSc CS/2022/2022.1/7. DLMDSEDE02 Project Data Engineering/4. Assignments/Deliverables/DLMDSEDE02-project-cmueller/tests-and-examples/Volve F.edm.xml\", parser=p)\n",
    "root = tree.getroot()\n",
    "\n",
    "# RETURN LIST OF ATTRIBUTE DICTIONARIES\n",
    "result_values = [dict(n.attrib) for n in root.findall(\".//CD_WELL\")]\n",
    "\n",
    "# RETRIEVE UNIQUE KEYS FOR COLUMN HEADERS\n",
    "keys = list({k for dct in result_values for k in dct})\n",
    "\n",
    "with open('test.csv', 'w') as f:\n",
    "    # WRITE TO CSV VIA DICTWRITER\n",
    "    dw = csv.DictWriter(f, fieldnames=keys)\n",
    "    dw.writeheader()\n",
    "    dw.writerows(result_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wellbore_id = []\n",
    "\n",
    "#get actual surveys for valid wellbores\n",
    "for child in root:\n",
    "    if child.tag == 'CD_DEFINITIVE_SURVEY_HEADER':\n",
    "        if child.attrib['phase'] == 'ACTUAL':\n",
    "            wellbore_id.append(child.attrib['wellbore_id'])\n",
    "\n",
    "# create a list of wellbore names for the ids found\n",
    "wellbore_name = []\n",
    "\n",
    "for child in root:\n",
    "    if child.tag == 'CD_WELLBORE':\n",
    "        if child.attrib['wellbore_id'] in wellbore_id:\n",
    "            wellbore_name.append(child.attrib['well_legal_name'].replace('/','-'))\n",
    "\n",
    "# make a dictionary holding wellbore ids as keys and wellbore names as values\n",
    "id_name_dict = dict(zip(wellbore_id, wellbore_name))\n",
    "\n",
    "id_name_dict\n",
    "\n",
    "wellbores = pd.DataFrame(list(id_name_dict.items()), columns=['wellbore_key', 'wellbore_name'])\n",
    "wellbores.to_csv('wellbores.csv', sep = ';', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to extract trajectory data from the database\n",
    "def get_wellpath(dct):\n",
    "    survey_header = []\n",
    "# consider only actual wellbores\n",
    "    for child in root:\n",
    "        if child.tag == 'CD_DEFINITIVE_SURVEY_HEADER':\n",
    "            if child.attrib['phase'] == 'ACTUAL':\n",
    "                survey_header.append(child.attrib['def_survey_header_id'])\n",
    "\n",
    "    # for loop to collect data for every wellbore in the dictionary that was created earlier\n",
    "    for key in dct:\n",
    "        # append wellpath data to corresponding lists\n",
    "        for item in survey_header:\n",
    "            azimuth = []\n",
    "            inclination = []\n",
    "            md = []\n",
    "            tvd = []\n",
    "            easting = []\n",
    "            northing = []\n",
    "    for child in root:\n",
    "        if child.tag == 'CD_DEFINITIVE_SURVEY_STATION':\n",
    "            if child.attrib['wellbore_id'] == key:\n",
    "                if child.attrib['def_survey_header_id'] == item:\n",
    "                    azimuth.append(float(child.attrib['azimuth']))\n",
    "                    inclination.append(float(child.attrib['inclination']))\n",
    "                    md.append(float(child.attrib['md']) * 0.3048)\n",
    "                    tvd.append(float(child.attrib['tvd']) * 0.3048)\n",
    "                    easting.append(float(child.attrib['offset_east']) * 0.3048)\n",
    "                    northing.append(float(child.attrib['offset_north']) * 0.3048)\n",
    "                    # create a dataframe and save the dataframe as csv file\n",
    "                    if md:\n",
    "                        wellpath = pd.DataFrame(list(zip(key,item, md, azimuth, inclination)), columns=[\n",
    "                                                        'Wellbore', 'SurveyID', 'MeasuredDepth', 'Azimuth', 'Inclination'])\n",
    "                        wellpath.sort_values(\n",
    "                                    'MeasuredDepth', inplace=True)\n",
    "                        wellpath = wellpath.reset_index(drop=True)\n",
    "                        wellpath.to_csv(\n",
    "                                    'trajectories.csv', sep=';', index=False)\n",
    "                        \n",
    "# run function\n",
    "get_wellpath(dict(id_name_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['well_id', 'wellbore_id', 'def_survey_header_id',\n",
      "       'definitive_survey_id', 'azimuth', 'offset_east', 'offset_north',\n",
      "       'covariance_yy', 'sequence_no', 'ellipse_vertical', 'covariance_yz',\n",
      "       'covariance_zz', 'covariance_xx', 'data_entry_mode', 'covariance_xy',\n",
      "       'dogleg_severity', 'inclination', 'covariance_xz', 'ellipse_east',\n",
      "       'ellipse_north', 'md', 'casing_radius', 'tvd', 'global_lateral_error'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 25/110 [00:00<00:00, 245.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iM93r is missing data\n",
      "MQ9kY is missing data\n",
      "dssSF is missing data\n",
      "qNnjC is missing data\n",
      "j7NXn is missing data\n",
      "oK87K is missing data\n",
      "1uO4j is missing data\n",
      "XxMvr is missing data\n",
      "8DKIV is missing data\n",
      "YnAAW is missing data\n",
      "EwmZ5 is missing data\n",
      "o95jZ is missing data\n",
      "rLwoj is missing data\n",
      "i97aF is missing data\n",
      "spG40 is missing data\n",
      "fmslR is missing data\n",
      "xVlDe is missing data\n",
      "5koyF is missing data\n",
      "kPYLQ is missing data\n",
      "AtCw9 is missing data\n",
      "TjpU0 is missing data\n",
      "xUiAs is missing data\n",
      "RJvOg is missing data\n",
      "130WO is missing data\n",
      "rPeEV is missing data\n",
      "AZ2V0 is missing data\n",
      "OPfEC is missing data\n",
      "cBKyI is missing data\n",
      "iNQEP is missing data\n",
      "3Dwwx is missing data\n",
      "SmYml is missing data\n",
      "ciwa5 is missing data\n",
      "iFoyo is missing data\n",
      "3sPcx is missing data\n",
      "wKp2v is missing data\n",
      "AUHLm is missing data\n",
      "NfcaY is missing data\n",
      "2GcVx is missing data\n",
      "2IGnP is missing data\n",
      "4IAae is missing data\n",
      "7e1bm is missing data\n",
      "fu7hx is missing data\n",
      "HEmVH is missing data\n",
      "LIfwp is missing data\n",
      "muCxJ is missing data\n",
      "Wmx1q is missing data\n",
      "3QVNa is missing data\n",
      "6q2F8 is missing data\n",
      "aNKjF is missing data\n",
      "BDJX7 is missing data\n",
      "Hu6nX is missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 53/110 [00:00<00:00, 262.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lifXe is missing data\n",
      "LRJoo is missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:00<00:00, 273.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QKeIK is missing data\n",
      "tRRR2 is missing data\n",
      "Rh5MS is missing data\n",
      "rmMIg is missing data\n",
      "Ycx3f is missing data\n",
      "43Y6O is missing data\n",
      "e21zN is missing data\n",
      "hUW4a is missing data\n",
      "8i3Ou is missing data\n",
      "rUF3x is missing data\n",
      "80RgO is missing data\n",
      "BY9cr is missing data\n",
      "stsNP is missing data\n",
      "lRiYY is missing data\n",
      "7aduA is missing data\n",
      "WFIYJ is missing data\n",
      "p4SIc is missing data\n",
      "uephK is missing data\n",
      "iR37P is missing data\n",
      "RQbFu is missing data\n",
      "xd2sG is missing data\n",
      "sk6RL is missing data\n",
      "3nuBn is missing data\n",
      "XwUfN is missing data\n",
      "hsgAy is missing data\n",
      "jjOt3 is missing data\n",
      "LwXck is missing data\n",
      "NNHEM is missing data\n",
      "uy9rE is missing data\n",
      "MmcSN is missing data\n",
      "Vwr9M is missing data\n",
      "0sWM5 is missing data\n",
      "eu6BT is missing data\n",
      "qUnn8 is missing data\n",
      "W4jxd is missing data\n",
      "DNxfH is missing data\n",
      "9vYsN is missing data\n",
      "Qrl38 is missing data\n",
      "wsFQ6 is missing data\n",
      "bFpXf is missing data\n",
      "D2jo7 is missing data\n",
      "AuyUw is missing data\n",
      "cisjk is missing data\n",
      "GC4P9 is missing data\n",
      "l5EDg is missing data\n",
      "op9m2 is missing data\n",
      "qAvcg is missing data\n",
      "QBcjd is missing data\n",
      "SSRgw is missing data\n",
      "DRduy is missing data\n",
      "wKJN9 is missing data\n",
      "fEcQP is missing data\n",
      "YHbZ7 is missing data\n",
      "Fkaeq is missing data\n",
      "wnOAa is missing data\n",
      "iN9YD is missing data\n",
      "Pz4XL is missing data\n",
      "Making a scene and plotting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import welleng as we\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "# import os\n",
    "\n",
    "# os.environ['DISPLAY'] = ':1'\n",
    "\n",
    "# for ease I accessed the data file locally and gave it a\n",
    "# shorter name. You'll need to change this to reflect the\n",
    "# local location of the data file.\n",
    "filename = '/Users/christianmueller/Library/Mobile Documents/com~apple~CloudDocs/Studies/Academic/5. MSc CS/2022/2022.1/7. DLMDSEDE02 Project Data Engineering/4. Assignments/Deliverables/DLMDSEDE02-project-cmueller/tests-and-examples/Volve F.edm.xml'\n",
    "\n",
    "# read the WITSML data\n",
    "#print(\"Importing the data...\")\n",
    "try:\n",
    "    tree = ET.parse(filename)\n",
    "    root = tree.getroot()\n",
    "except:\n",
    "    print(\"Please download the volve data and point filename to its location\")\n",
    "\n",
    "# extract the survey data and create a dataframe\n",
    "#print(\"Extracting survey data...\")\n",
    "survey_data = [\n",
    "    c.attrib for c in root\n",
    "    if c.tag == \"CD_DEFINITIVE_SURVEY_STATION\"\n",
    "]\n",
    "df = pd.DataFrame(survey_data)\n",
    "df['md'] = df['md'].astype(float)\n",
    "wells = df['def_survey_header_id'].unique()\n",
    "\n",
    "data = {}\n",
    "\n",
    "#print(\"Processing wells...\")\n",
    "# this is a bit slow... multithread this if you want to do it faster\n",
    "for well in tqdm(wells):\n",
    "    sh = we.survey.SurveyHeader(\n",
    "        name=well,\n",
    "        azi_reference=\"grid\"\n",
    "    )\n",
    "    w = df.loc[\n",
    "        df['def_survey_header_id'] == well\n",
    "    ].sort_values(by=['md'])\n",
    "    cov_nev = we.survey.make_long_cov(np.array([\n",
    "        w['covariance_yy'],\n",
    "        w['covariance_xy'],\n",
    "        w['covariance_yz'],\n",
    "        w['covariance_xx'],\n",
    "        w['covariance_xz'],\n",
    "        w['covariance_zz']\n",
    "    ]).T).astype(float)\n",
    "\n",
    "    # radius data is sometimes missing or zero and looks to be in inches\n",
    "    # default these to 15\" radius and convert to meters\n",
    "    radius = np.array(w['casing_radius']).astype(float)\n",
    "    radius = np.where(((radius == np.nan) | (radius == 0)), 15, radius)\n",
    "    radius *= 0.0254\n",
    "\n",
    "    s = we.survey.Survey(\n",
    "        md=np.array(w['md']).astype(float) / 3.281,\n",
    "        inc=np.array(w['inclination']).astype(float),\n",
    "        azi=np.array(w['azimuth']).astype(float),\n",
    "        n=np.array(w['offset_north']).astype(float),\n",
    "        e=np.array(w['offset_east']).astype(float),\n",
    "        tvd=np.array(w['tvd']).astype(float) / 3.281,  # appears that TVD data is in feet?\n",
    "        header=sh,\n",
    "        cov_nev=cov_nev,\n",
    "        radius=radius\n",
    "    )\n",
    "\n",
    "    # some wells are missing covariance data: skip those for now\n",
    "    try:\n",
    "        m = we.mesh.WellMesh(s)\n",
    "        data[well] = m\n",
    "        print(data)\n",
    "    except:\n",
    "        print(f\"{well} is missing data\")\n",
    "\n",
    "# create a trimesh scene and plot with welleng plotter\n",
    "print(\"Making a scene and plotting...\")\n",
    "#scene = we.mesh.make_trimesh_scene(data)\n",
    "#we.visual.plot(scene)\n",
    "\n",
    "#print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
